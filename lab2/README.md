Задача: реализовать алгоритм сложения элементов вектора
Язык: C++ или Python
Входные данные: Вектор размером 1 000..1 000 000 значений.
Выходные данные: сумма элементов вектора + время вычисления
Реализация должна содержать 2 функции сложения элементов вектора: на CPU и на
GPU с применением CUDA.
Отчет о проделанной лабораторной работе - это git-репозиторий с исходным кодом
реализации + описание проделанной работы там же в readme.
Необходимо описать реализацию, объяснив, что конкретно было распараллелено и
почему.
Провести эксперименты: получить сумму векторов разных размеров (провести 5 или
более экспериментов), посчитать ускорение. Результаты привести в виде
таблицы/графика.

Техническое обеспечение: Графический процессор, использованный в Colab, Nvidia K80s Tesla. Процессор: AMD Ryzen 5 3500U with Radeon Vega Mobile Gfx, 2096 МГц ОЗУ - 8,00 ГБ (доступно: 7,1 ГБ) Система - Windows 10 (Версия 10.0.19042.1237) Язык реализации программы - Python 3.9.2 Описание: На вход функцииям подается вектор, случайно сгенерированный с помощью np.random.randn с размером 1000, 10_000, 100_000, 1_000_000.

Реализованы 3 функции в отдельных блоках "google colab".

Был использован компилятор "numba jit", который переводит сколько возможно когда python - в машинный код, тем самым ускоряя процесс выполнения программы.

Для визуализации полученных данных о времени выполнения был реализован датафрейм, в котором указан тип процессора, на котором выполнялся расчёт, за сколько времени он был выполнен и какую размерность имели вектора.

![image](https://user-images.githubusercontent.com/80954194/139470901-97a87d80-5281-4294-b6ac-a339fe3feee3.png)

В конце был подведён итог работы функции на всех видах расчётов.


